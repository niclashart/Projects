\cleardoubleoddpage

\chapter*{Kurzfassung}
\thispagestyle{empty} %hide page numbers
Diese Arbeit entwickelt ein Retrieval‑Augmented‑Generation (RAG) System zur mehrsprachigen Informationsbereitstellung aus technischen Produktdatenblättern von Thin‑Clients (Laptops) und Monitoren. 
Als Datengrundlage wurden ca. 1500 Datenblätter verwendet. 
Die Pipeline extrahiert Inhalte mit PyPDF, segmentiert und tokenisiert die Textteile, erzeugt Vektor‑Repräsentationen und speichert sie in einem hybriden Vector‑Store (FAISS mit Chroma für Metadaten). 
Die Orchestrierung erfolgt mit LangChain; als generatives Modell wird OpenAI GPT‑5 mini eingesetzt, das kontextuell durch Retrieval‑Ergebnisse ergänzt wird. 

Zur Evaluation wurden Retrieval‑Metriken (Recall@k, MRR) sowie extraktions‑ und antwortbezogene Metriken (F1, Genauigkeit) verwendet. 
Die Experimente zeigen, dass die Kombination aus spezialisiertem Vector‑Store und RAG gegenüber reinem Prompting signifikant bessere Präzision und stabilere Antworten in mehreren Sprachen liefert. 

Die Arbeit liefert (1) eine implementierbare RAG‑Pipeline für technische Dokumente, 
(2) eine Evaluationsprozedur zur quantitativen und qualitativen Bewertung, 
und (3) Hinweise zur Praxis (Chunk‑Strategien, Embedding‑Konfiguration, Kosten/Antwortlatenz). 
Code und Datenverarbeitungsskripte sind zur Reproduzierbarkeit in einem öffentlichen Repository verfügbar.